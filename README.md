# ğŸ›’ Mercado Libre - Data Engineer Challenge

Este repositorio contiene la soluciÃ³n al challenge tÃ©cnico para la posiciÃ³n de **Data Engineer** en Mercado Libre. Se abordan los aspectos de modelado de datos, carga de informaciÃ³n, consultas de negocio y automatizaciÃ³n con cron.

---

## ğŸ“ Estructura del proyecto

```
meli-data-engineer-challenge/
â”œâ”€â”€ create_tables.sql               # DDL para crear las tablas en PostgreSQL
â”œâ”€â”€ cargar_csv_postgres.py          # Script Python para cargar CSVs a PostgreSQL
â”œâ”€â”€ programar_snapshot_cron.sql     # Crea un job con pg_cron para snapshot diario
â”œâ”€â”€ docker-compose.yml              # Configura PostgreSQL + pgAdmin + pg_cron
â”œâ”€â”€ Dockerfile                      # Imagen personalizada con pg_cron compilado
â”œâ”€â”€ init_pgcron.sql                 # Habilita la extensiÃ³n pg_cron
â”œâ”€â”€ requirements.txt                # Dependencias Python
â”œâ”€â”€ .env.example                    # Variables de entorno
â”œâ”€â”€ respuestas_negocio.sql          # Consultas para resolver las consignas
â”œâ”€â”€ mock_data/                      # CSVs generados con datos simulados
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ pyspark_challenge_notebook.ipynb
â””â”€â”€ diagramas/
    â””â”€â”€ DER_MercadoLibre_Modelo.png
```

---

## âš™ï¸ Requisitos

- Docker + Docker Compose
- Python 3.9+
- pip

---

## ğŸš€ CÃ³mo ejecutar el proyecto

### 1. Clonar el repositorio

```bash
git clone https://github.com/tu_usuario/meli-data-engineer-challenge.git
cd meli-data-engineer-challenge
```

### 2. Configurar variables de entorno

```bash
cp .env.example .env
```

### 3. Levantar la base de datos y pgAdmin

```bash
docker compose up -d --build
```

pgAdmin estarÃ¡ disponible en [http://localhost:8080](http://localhost:8080)

- Email: `admin@example.com`
- Password: `admin`

---

### 4. Crear las tablas

```bash
psql -U postgres -d meli_challenge -f create_tables.sql
```

---

### 5. Cargar los datos desde los CSV

```bash
pip install -r requirements.txt
python cargar_csv_postgres.py
```

---

### 6. Programar snapshot diario con pg_cron

```bash
psql -U postgres -d meli_challenge -f programar_snapshot_cron.sql
```

---

### 7. Ejecutar consultas de negocio

```bash
psql -U postgres -d meli_challenge -f respuestas_negocio.sql
```

---

## ğŸ§  Consultas incluidas

- Clientes que cumplen aÃ±os hoy y vendieron mÃ¡s de $1500 en enero 2020
- Top 5 vendedores mensuales en categorÃ­a "Celulares"
- Registro diario en `item_history` (automatizado con `pg_cron`)

---

## ğŸ“Š AnÃ¡lisis en Spark (opcional)

En `notebooks/pyspark_challenge_notebook.ipynb` se muestra cÃ³mo resolver las consultas usando Spark SQL.

PodÃ©s ejecutarlo directamente en [Google Colab](https://colab.research.google.com/) cargando tus archivos CSV.

---

## ğŸ§¾ Licencia

Este proyecto fue desarrollado como parte de un ejercicio tÃ©cnico. PodÃ©s usarlo como referencia educativa.